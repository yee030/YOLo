{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yee030/YOLo/blob/main/YOLo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOu9xmcz1zwC",
        "outputId": "5e8762c5-2ad7-4ab1-b63c-4c965d6d3cd3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOv5 ğŸš€ v7.0-218-g9e97ac3 Python-3.10.12 torch-2.0.1+cu118 CPU\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 26.3/107.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "# GitHubì—ì„œ YOLOv5 ë ˆí¬ì§€í† ë¦¬ë¥¼ ë³µì œí•©ë‹ˆë‹¤.\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "\n",
        "# yolov5 ë””ë ‰í† ë¦¬ë¡œ ì´ë™í•©ë‹ˆë‹¤.\n",
        "%cd yolov5\n",
        "\n",
        "# requirements.txt íŒŒì¼ì— ëª…ì‹œëœ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° comet_ml ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
        "%pip install -qr requirements.txt comet_ml  # install\n",
        "\n",
        "# PyTorch ë° ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ˆê¸°í™”í•˜ì—¬ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # í™˜ê²½ ì´ˆê¸°í™” ë° ë…¸íŠ¸ë¶ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyP1cGHc2BPh",
        "outputId": "fdec001e-73fa-4a46-c152-8290f146b828"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ğŸš€ v7.0-218-g9e97ac3 Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 91.9MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "image 1/2 /content/yolov5/data/images/bus.jpg: 640x480 4 persons, 1 bus, 398.3ms\n",
            "image 2/2 /content/yolov5/data/images/zidane.jpg: 384x640 2 persons, 2 ties, 382.4ms\n",
            "Speed: 2.3ms pre-process, 390.4ms inference, 18.6ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# YOLOv5ë¡œ ê°ì²´ íƒì§€ ìˆ˜í–‰í•˜ëŠ” ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
        "# --weights yolov5s.pt: ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼(yolov5s.pt)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "# --img 640: ì…ë ¥ ì´ë¯¸ì§€ì˜ í¬ê¸°ë¥¼ 640x640 í”½ì…€ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
        "# --conf 0.25: ì‹ ë¢°ë„ ì„ê³„ê°’ì„ 0.25ë¡œ ì„¤ì •í•˜ì—¬ ë‚®ì€ í™•ë¥ ì˜ ì˜ˆì¸¡ë„ í‘œì‹œí•©ë‹ˆë‹¤.\n",
        "# --source data/images: íƒì§€ë¥¼ ìˆ˜í–‰í•  ì´ë¯¸ì§€ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.\n",
        "!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data/images\n",
        "\n",
        "# ì•„ë˜ ì£¼ì„ì€ ì´ë¯¸ì§€ë¥¼ ì¶œë ¥í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤. (ë…¸íŠ¸ë¶ í™˜ê²½ì—ì„œ ì‚¬ìš©)\n",
        "# display.Image(filename='runs/detect/exp/zidane.jpg', width=600)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F93imDxE2ESA",
        "outputId": "31412fdb-7f83-4423-f3fc-18218612ca72"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 780M/780M [00:14<00:00, 55.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download COCO val\n",
        "torch.hub.download_url_to_file('https://ultralytics.com/assets/coco2017val.zip', 'tmp.zip')  # download (780M - 5000 images)\n",
        "!unzip -q tmp.zip -d ../datasets && rm tmp.zip  # unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mA1-Ep2n6qp8",
        "outputId": "a4676266-b056-4781-c8d5-e3f9e4471f08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/data/coco.yaml, weights=['yolov5s.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False\n",
            "YOLOv5 ğŸš€ v7.0-218-g9e97ac3 Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco/val2017... 4952 images, 48 backgrounds, 0 corrupt: 100% 5000/5000 [00:03<00:00, 1500.61it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco/val2017.cache\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/157 [00:01<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/yolov5/val.py\", line 411, in <module>\n",
            "    main(opt)\n",
            "  File \"/content/yolov5/val.py\", line 382, in main\n",
            "    run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/yolov5/val.py\", line 210, in run\n",
            "    preds, train_out = model(im) if compute_loss else (model(im, augment=augment), None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/yolov5/models/common.py\", line 527, in forward\n",
            "    y = self.model(im, augment=augment, visualize=visualize) if augment or visualize else self.model(im)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/yolov5/models/yolo.py\", line 209, in forward\n",
            "    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n",
            "  File \"/content/yolov5/models/yolo.py\", line 121, in _forward_once\n",
            "    x = m(x)  # run\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/yolov5/models/common.py\", line 71, in forward_fuse\n",
            "    return self.act(self.conv(x))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
            "    return F.conv2d(input, weight, bias, self.stride,\n",
            "RuntimeError: \"slow_conv2d_cpu\" not implemented for 'Half'\n"
          ]
        }
      ],
      "source": [
        "# Validate YOLOv5s on COCO val\n",
        "!python val.py --weights yolov5s.pt --data coco.yaml --img 640 --half"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LP4kRDF6tRB",
        "outputId": "8caa1473-b732-462f-e1c0-9aa74359e43e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please paste your Comet API key from https://www.comet.com/api/my/settings/\n",
            "(api key may not show as you type)\n"
          ]
        }
      ],
      "source": [
        "#@title Select YOLOv5 ğŸš€ logger {run: 'auto'}\n",
        "logger = 'Comet' #@param ['Comet', 'ClearML', 'TensorBoard']\n",
        "\n",
        "if logger == 'Comet':\n",
        "  %pip install -q comet_ml\n",
        "  import comet_ml; comet_ml.init()\n",
        "elif logger == 'ClearML':\n",
        "  %pip install -q clearml\n",
        "  import clearml; clearml.browser_login()\n",
        "elif logger == 'TensorBoard':\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir runs/train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjYuvpJf6vXh"
      },
      "outputs": [],
      "source": [
        "# Train YOLOv5s on COCO128 for 3 epochs\n",
        "!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt --cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EI_OIjhX6w8w"
      },
      "outputs": [],
      "source": [
        "# YOLOv5 PyTorch HUB Inference (DetectionModels only)\n",
        "import torch\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True)  # yolov5n - yolov5x6 or custom\n",
        "im = 'https://ultralytics.com/images/zidane.jpg'  # file, Path, PIL.Image, OpenCV, nparray, list\n",
        "results = model(im)  # inference\n",
        "results.print()  # or .show(), .save(), .crop(), .pandas(), etc."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9P45XyMf9Yd3v2FUAE1Ln",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}